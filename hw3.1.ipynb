{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Homework #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutionary Neural Network Implementation for HOMEWORK 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train shape:', (724, 150))\n",
      "('X_test shape:', (242, 150))\n",
      "(724, 'train samples')\n",
      "(242, 'test samples')\n",
      "('Y_train shape:', (724, 8))\n",
      "('Y_test shape:', (242, 8))\n",
      "Train on 724 samples, validate on 242 samples\n",
      "Epoch 1/120\n",
      "724/724 [==============================] - 0s - loss: 1.8697 - acc: 0.4075 - val_loss: 1.8008 - val_acc: 0.3802\n",
      "Epoch 2/120\n",
      "724/724 [==============================] - 0s - loss: 1.7018 - acc: 0.4185 - val_loss: 1.7850 - val_acc: 0.3802\n",
      "Epoch 3/120\n",
      "724/724 [==============================] - 0s - loss: 1.6854 - acc: 0.4185 - val_loss: 1.7707 - val_acc: 0.3802\n",
      "Epoch 4/120\n",
      "724/724 [==============================] - 0s - loss: 1.6796 - acc: 0.4185 - val_loss: 1.7673 - val_acc: 0.3802\n",
      "Epoch 5/120\n",
      "724/724 [==============================] - 0s - loss: 1.6762 - acc: 0.4185 - val_loss: 1.7653 - val_acc: 0.3802\n",
      "Epoch 6/120\n",
      "724/724 [==============================] - 0s - loss: 1.6820 - acc: 0.4185 - val_loss: 1.7694 - val_acc: 0.3802\n",
      "Epoch 7/120\n",
      "724/724 [==============================] - 0s - loss: 1.6744 - acc: 0.4185 - val_loss: 1.7580 - val_acc: 0.3802\n",
      "Epoch 8/120\n",
      "724/724 [==============================] - 0s - loss: 1.6722 - acc: 0.4185 - val_loss: 1.7606 - val_acc: 0.3802\n",
      "Epoch 9/120\n",
      "724/724 [==============================] - 0s - loss: 1.6807 - acc: 0.4185 - val_loss: 1.7562 - val_acc: 0.3802\n",
      "Epoch 10/120\n",
      "724/724 [==============================] - 0s - loss: 1.6775 - acc: 0.4185 - val_loss: 1.7507 - val_acc: 0.3802\n",
      "Epoch 11/120\n",
      "724/724 [==============================] - 0s - loss: 1.6689 - acc: 0.4185 - val_loss: 1.7697 - val_acc: 0.3802\n",
      "Epoch 12/120\n",
      "724/724 [==============================] - 0s - loss: 1.6766 - acc: 0.4185 - val_loss: 1.7599 - val_acc: 0.3802\n",
      "Epoch 13/120\n",
      "724/724 [==============================] - 0s - loss: 1.6724 - acc: 0.4185 - val_loss: 1.7683 - val_acc: 0.3802\n",
      "Epoch 14/120\n",
      "724/724 [==============================] - 0s - loss: 1.6757 - acc: 0.4185 - val_loss: 1.7633 - val_acc: 0.3802\n",
      "Epoch 15/120\n",
      "724/724 [==============================] - 0s - loss: 1.6857 - acc: 0.4185 - val_loss: 1.7546 - val_acc: 0.3802\n",
      "Epoch 16/120\n",
      "724/724 [==============================] - 0s - loss: 1.6722 - acc: 0.4185 - val_loss: 1.7567 - val_acc: 0.3802\n",
      "Epoch 17/120\n",
      "724/724 [==============================] - 0s - loss: 1.6693 - acc: 0.4185 - val_loss: 1.7695 - val_acc: 0.3802\n",
      "Epoch 18/120\n",
      "724/724 [==============================] - 0s - loss: 1.6769 - acc: 0.4185 - val_loss: 1.7552 - val_acc: 0.3802\n",
      "Epoch 19/120\n",
      "724/724 [==============================] - 0s - loss: 1.6673 - acc: 0.4185 - val_loss: 1.7616 - val_acc: 0.3802\n",
      "Epoch 20/120\n",
      "724/724 [==============================] - 0s - loss: 1.6766 - acc: 0.4185 - val_loss: 1.7601 - val_acc: 0.3802\n",
      "Epoch 21/120\n",
      "724/724 [==============================] - 0s - loss: 1.6735 - acc: 0.4185 - val_loss: 1.7565 - val_acc: 0.3802\n",
      "Epoch 22/120\n",
      "724/724 [==============================] - 0s - loss: 1.6707 - acc: 0.4185 - val_loss: 1.7575 - val_acc: 0.3802\n",
      "Epoch 23/120\n",
      "724/724 [==============================] - 0s - loss: 1.6738 - acc: 0.4185 - val_loss: 1.7561 - val_acc: 0.3802\n",
      "Epoch 24/120\n",
      "724/724 [==============================] - 0s - loss: 1.6784 - acc: 0.4185 - val_loss: 1.7652 - val_acc: 0.3802\n",
      "Epoch 25/120\n",
      "724/724 [==============================] - 0s - loss: 1.6707 - acc: 0.4185 - val_loss: 1.7732 - val_acc: 0.3802\n",
      "Epoch 26/120\n",
      "724/724 [==============================] - 0s - loss: 1.6656 - acc: 0.4185 - val_loss: 1.7574 - val_acc: 0.3802\n",
      "Epoch 27/120\n",
      "724/724 [==============================] - 0s - loss: 1.6749 - acc: 0.4185 - val_loss: 1.7582 - val_acc: 0.3802\n",
      "Epoch 28/120\n",
      "724/724 [==============================] - 0s - loss: 1.6683 - acc: 0.4185 - val_loss: 1.7560 - val_acc: 0.3802\n",
      "Epoch 29/120\n",
      "724/724 [==============================] - 0s - loss: 1.6663 - acc: 0.4185 - val_loss: 1.7563 - val_acc: 0.3802\n",
      "Epoch 30/120\n",
      "724/724 [==============================] - 0s - loss: 1.6716 - acc: 0.4185 - val_loss: 1.7557 - val_acc: 0.3802\n",
      "Epoch 31/120\n",
      "724/724 [==============================] - 0s - loss: 1.6704 - acc: 0.4185 - val_loss: 1.7503 - val_acc: 0.3802\n",
      "Epoch 32/120\n",
      "724/724 [==============================] - 0s - loss: 1.6677 - acc: 0.4185 - val_loss: 1.7593 - val_acc: 0.3802\n",
      "Epoch 33/120\n",
      "724/724 [==============================] - 0s - loss: 1.6668 - acc: 0.4185 - val_loss: 1.7611 - val_acc: 0.3802\n",
      "Epoch 34/120\n",
      "724/724 [==============================] - 0s - loss: 1.6724 - acc: 0.4185 - val_loss: 1.7546 - val_acc: 0.3802\n",
      "Epoch 35/120\n",
      "724/724 [==============================] - 0s - loss: 1.6743 - acc: 0.4185 - val_loss: 1.7504 - val_acc: 0.3802\n",
      "Epoch 36/120\n",
      "724/724 [==============================] - 0s - loss: 1.6715 - acc: 0.4185 - val_loss: 1.7601 - val_acc: 0.3802\n",
      "Epoch 37/120\n",
      "724/724 [==============================] - 0s - loss: 1.6769 - acc: 0.4185 - val_loss: 1.7561 - val_acc: 0.3802\n",
      "Epoch 38/120\n",
      "724/724 [==============================] - 0s - loss: 1.6707 - acc: 0.4185 - val_loss: 1.7540 - val_acc: 0.3802\n",
      "Epoch 39/120\n",
      "724/724 [==============================] - 0s - loss: 1.6726 - acc: 0.4185 - val_loss: 1.7503 - val_acc: 0.3802\n",
      "Epoch 40/120\n",
      "724/724 [==============================] - 0s - loss: 1.6639 - acc: 0.4185 - val_loss: 1.7532 - val_acc: 0.3802\n",
      "Epoch 41/120\n",
      "724/724 [==============================] - 0s - loss: 1.6739 - acc: 0.4185 - val_loss: 1.7527 - val_acc: 0.3802\n",
      "Epoch 42/120\n",
      "724/724 [==============================] - 0s - loss: 1.6707 - acc: 0.4185 - val_loss: 1.7533 - val_acc: 0.3802\n",
      "Epoch 43/120\n",
      "724/724 [==============================] - 0s - loss: 1.6702 - acc: 0.4185 - val_loss: 1.7542 - val_acc: 0.3802\n",
      "Epoch 44/120\n",
      "724/724 [==============================] - 0s - loss: 1.6697 - acc: 0.4185 - val_loss: 1.7557 - val_acc: 0.3802\n",
      "Epoch 45/120\n",
      "724/724 [==============================] - 0s - loss: 1.6740 - acc: 0.4185 - val_loss: 1.7579 - val_acc: 0.3802\n",
      "Epoch 46/120\n",
      "724/724 [==============================] - 0s - loss: 1.6716 - acc: 0.4185 - val_loss: 1.7544 - val_acc: 0.3802\n",
      "Epoch 47/120\n",
      "724/724 [==============================] - 0s - loss: 1.6671 - acc: 0.4185 - val_loss: 1.7567 - val_acc: 0.3802\n",
      "Epoch 48/120\n",
      "724/724 [==============================] - 0s - loss: 1.6709 - acc: 0.4185 - val_loss: 1.7556 - val_acc: 0.3802\n",
      "Epoch 49/120\n",
      "724/724 [==============================] - 0s - loss: 1.6788 - acc: 0.4185 - val_loss: 1.7598 - val_acc: 0.3802\n",
      "Epoch 50/120\n",
      "724/724 [==============================] - 0s - loss: 1.6665 - acc: 0.4185 - val_loss: 1.7499 - val_acc: 0.3802\n",
      "Epoch 51/120\n",
      "724/724 [==============================] - 0s - loss: 1.6683 - acc: 0.4185 - val_loss: 1.7511 - val_acc: 0.3802\n",
      "Epoch 52/120\n",
      "724/724 [==============================] - 0s - loss: 1.6661 - acc: 0.4185 - val_loss: 1.7536 - val_acc: 0.3802\n",
      "Epoch 53/120\n",
      "724/724 [==============================] - 0s - loss: 1.6675 - acc: 0.4185 - val_loss: 1.7530 - val_acc: 0.3802\n",
      "Epoch 54/120\n",
      "724/724 [==============================] - 0s - loss: 1.6706 - acc: 0.4185 - val_loss: 1.7549 - val_acc: 0.3802\n",
      "Epoch 55/120\n",
      "724/724 [==============================] - 0s - loss: 1.6687 - acc: 0.4185 - val_loss: 1.7528 - val_acc: 0.3802\n",
      "Epoch 56/120\n",
      "724/724 [==============================] - 0s - loss: 1.6709 - acc: 0.4185 - val_loss: 1.7527 - val_acc: 0.3802\n",
      "Epoch 57/120\n",
      "724/724 [==============================] - 0s - loss: 1.6693 - acc: 0.4185 - val_loss: 1.7627 - val_acc: 0.3802\n",
      "Epoch 58/120\n",
      "724/724 [==============================] - 0s - loss: 1.6700 - acc: 0.4185 - val_loss: 1.7512 - val_acc: 0.3802\n",
      "Epoch 59/120\n",
      "724/724 [==============================] - 0s - loss: 1.6684 - acc: 0.4185 - val_loss: 1.7504 - val_acc: 0.3802\n",
      "Epoch 60/120\n",
      "724/724 [==============================] - 0s - loss: 1.6660 - acc: 0.4185 - val_loss: 1.7598 - val_acc: 0.3802\n",
      "Epoch 61/120\n",
      "724/724 [==============================] - 0s - loss: 1.6674 - acc: 0.4185 - val_loss: 1.7592 - val_acc: 0.3802\n",
      "Epoch 62/120\n",
      "724/724 [==============================] - 0s - loss: 1.6786 - acc: 0.4185 - val_loss: 1.7558 - val_acc: 0.3802\n",
      "Epoch 63/120\n",
      "724/724 [==============================] - 0s - loss: 1.6653 - acc: 0.4185 - val_loss: 1.7583 - val_acc: 0.3802\n",
      "Epoch 64/120\n",
      "724/724 [==============================] - 0s - loss: 1.6630 - acc: 0.4185 - val_loss: 1.7494 - val_acc: 0.3802\n",
      "Epoch 65/120\n",
      "724/724 [==============================] - 0s - loss: 1.6727 - acc: 0.4185 - val_loss: 1.7495 - val_acc: 0.3802\n",
      "Epoch 66/120\n",
      "724/724 [==============================] - 0s - loss: 1.6647 - acc: 0.4185 - val_loss: 1.7564 - val_acc: 0.3802\n",
      "Epoch 67/120\n",
      "724/724 [==============================] - 0s - loss: 1.6679 - acc: 0.4185 - val_loss: 1.7583 - val_acc: 0.3802\n",
      "Epoch 68/120\n",
      "724/724 [==============================] - 0s - loss: 1.6686 - acc: 0.4185 - val_loss: 1.7544 - val_acc: 0.3802\n",
      "Epoch 69/120\n",
      "724/724 [==============================] - 0s - loss: 1.6683 - acc: 0.4185 - val_loss: 1.7572 - val_acc: 0.3802\n",
      "Epoch 70/120\n",
      "724/724 [==============================] - 0s - loss: 1.6630 - acc: 0.4185 - val_loss: 1.7547 - val_acc: 0.3802\n",
      "Epoch 71/120\n",
      "724/724 [==============================] - 0s - loss: 1.6680 - acc: 0.4185 - val_loss: 1.7512 - val_acc: 0.3802\n",
      "Epoch 72/120\n",
      "724/724 [==============================] - 0s - loss: 1.6638 - acc: 0.4185 - val_loss: 1.7482 - val_acc: 0.3802\n",
      "Epoch 73/120\n",
      "724/724 [==============================] - 0s - loss: 1.6623 - acc: 0.4185 - val_loss: 1.7507 - val_acc: 0.3802\n",
      "Epoch 74/120\n",
      "724/724 [==============================] - 0s - loss: 1.6577 - acc: 0.4185 - val_loss: 1.7414 - val_acc: 0.3802\n",
      "Epoch 75/120\n",
      "724/724 [==============================] - 0s - loss: 1.6393 - acc: 0.4185 - val_loss: 1.7293 - val_acc: 0.3802\n",
      "Epoch 76/120\n",
      "724/724 [==============================] - 0s - loss: 1.5584 - acc: 0.4185 - val_loss: 1.5654 - val_acc: 0.3802\n",
      "Epoch 77/120\n",
      "724/724 [==============================] - 0s - loss: 1.3176 - acc: 0.4848 - val_loss: 1.4309 - val_acc: 0.4711\n",
      "Epoch 78/120\n",
      "724/724 [==============================] - 0s - loss: 1.2744 - acc: 0.5387 - val_loss: 1.4506 - val_acc: 0.4793\n",
      "Epoch 79/120\n",
      "724/724 [==============================] - 0s - loss: 1.1540 - acc: 0.5732 - val_loss: 1.5197 - val_acc: 0.4793\n",
      "Epoch 80/120\n",
      "724/724 [==============================] - 0s - loss: 1.1269 - acc: 0.5925 - val_loss: 1.5273 - val_acc: 0.4669\n",
      "Epoch 81/120\n",
      "724/724 [==============================] - 0s - loss: 1.0904 - acc: 0.5912 - val_loss: 1.7287 - val_acc: 0.4876\n",
      "Epoch 82/120\n",
      "724/724 [==============================] - 0s - loss: 1.0700 - acc: 0.5981 - val_loss: 1.6640 - val_acc: 0.4752\n",
      "Epoch 83/120\n",
      "724/724 [==============================] - 0s - loss: 1.0530 - acc: 0.6091 - val_loss: 1.6398 - val_acc: 0.4504\n",
      "Epoch 84/120\n",
      "724/724 [==============================] - 0s - loss: 1.0651 - acc: 0.5967 - val_loss: 1.5225 - val_acc: 0.4711\n",
      "Epoch 85/120\n",
      "724/724 [==============================] - 0s - loss: 1.0277 - acc: 0.6160 - val_loss: 1.6863 - val_acc: 0.4711\n",
      "Epoch 86/120\n",
      "724/724 [==============================] - 0s - loss: 1.0403 - acc: 0.5953 - val_loss: 1.6973 - val_acc: 0.4669\n",
      "Epoch 87/120\n",
      "724/724 [==============================] - 0s - loss: 1.0433 - acc: 0.6091 - val_loss: 1.6421 - val_acc: 0.4711\n",
      "Epoch 88/120\n",
      "724/724 [==============================] - 0s - loss: 1.0055 - acc: 0.6091 - val_loss: 1.6450 - val_acc: 0.4752\n",
      "Epoch 89/120\n",
      "724/724 [==============================] - 0s - loss: 0.9664 - acc: 0.6298 - val_loss: 1.6436 - val_acc: 0.4917\n",
      "Epoch 90/120\n",
      "724/724 [==============================] - 0s - loss: 0.8951 - acc: 0.6561 - val_loss: 1.7063 - val_acc: 0.4959\n",
      "Epoch 91/120\n",
      "724/724 [==============================] - 0s - loss: 0.8243 - acc: 0.6782 - val_loss: 1.7608 - val_acc: 0.5207\n",
      "Epoch 92/120\n",
      "724/724 [==============================] - 0s - loss: 0.7568 - acc: 0.6920 - val_loss: 1.7911 - val_acc: 0.5248\n",
      "Epoch 93/120\n",
      "724/724 [==============================] - 0s - loss: 0.6899 - acc: 0.7376 - val_loss: 1.7963 - val_acc: 0.5372\n",
      "Epoch 94/120\n",
      "724/724 [==============================] - 0s - loss: 0.6572 - acc: 0.7251 - val_loss: 1.9929 - val_acc: 0.5289\n",
      "Epoch 95/120\n",
      "724/724 [==============================] - 0s - loss: 0.6467 - acc: 0.7486 - val_loss: 2.1620 - val_acc: 0.5413\n",
      "Epoch 96/120\n",
      "724/724 [==============================] - 0s - loss: 0.6950 - acc: 0.7334 - val_loss: 2.0081 - val_acc: 0.5207\n",
      "Epoch 97/120\n",
      "724/724 [==============================] - 0s - loss: 0.7412 - acc: 0.7307 - val_loss: 1.9447 - val_acc: 0.5248\n",
      "Epoch 98/120\n",
      "724/724 [==============================] - 0s - loss: 0.5888 - acc: 0.7666 - val_loss: 2.2721 - val_acc: 0.5165\n",
      "Epoch 99/120\n",
      "724/724 [==============================] - 0s - loss: 0.5906 - acc: 0.7762 - val_loss: 2.3269 - val_acc: 0.5537\n",
      "Epoch 100/120\n",
      "724/724 [==============================] - 0s - loss: 0.6758 - acc: 0.7707 - val_loss: 2.0985 - val_acc: 0.4876\n",
      "Epoch 101/120\n",
      "724/724 [==============================] - 0s - loss: 0.6256 - acc: 0.7638 - val_loss: 1.8063 - val_acc: 0.5785\n",
      "Epoch 102/120\n",
      "724/724 [==============================] - 0s - loss: 0.5197 - acc: 0.7901 - val_loss: 1.9800 - val_acc: 0.5455\n",
      "Epoch 103/120\n",
      "724/724 [==============================] - 0s - loss: 0.4791 - acc: 0.8039 - val_loss: 2.2084 - val_acc: 0.5083\n",
      "Epoch 104/120\n",
      "724/724 [==============================] - 0s - loss: 0.4444 - acc: 0.8260 - val_loss: 2.0277 - val_acc: 0.5785\n",
      "Epoch 105/120\n",
      "724/724 [==============================] - 0s - loss: 0.4887 - acc: 0.7970 - val_loss: 2.2163 - val_acc: 0.5661\n",
      "Epoch 106/120\n",
      "724/724 [==============================] - 0s - loss: 0.6768 - acc: 0.7749 - val_loss: 2.4794 - val_acc: 0.5124\n",
      "Epoch 107/120\n",
      "724/724 [==============================] - 0s - loss: 0.8401 - acc: 0.7362 - val_loss: 1.7495 - val_acc: 0.6240\n",
      "Epoch 108/120\n",
      "724/724 [==============================] - 0s - loss: 0.7089 - acc: 0.7693 - val_loss: 1.4301 - val_acc: 0.6281\n",
      "Epoch 109/120\n",
      "724/724 [==============================] - 0s - loss: 0.5383 - acc: 0.8191 - val_loss: 1.4260 - val_acc: 0.6240\n",
      "Epoch 110/120\n",
      "724/724 [==============================] - 0s - loss: 0.5119 - acc: 0.8052 - val_loss: 1.5274 - val_acc: 0.6281\n",
      "Epoch 111/120\n",
      "724/724 [==============================] - 0s - loss: 0.4537 - acc: 0.8301 - val_loss: 1.8957 - val_acc: 0.6157\n",
      "Epoch 112/120\n",
      "724/724 [==============================] - 0s - loss: 0.4661 - acc: 0.8329 - val_loss: 1.9519 - val_acc: 0.5826\n",
      "Epoch 113/120\n",
      "724/724 [==============================] - 0s - loss: 0.4724 - acc: 0.8384 - val_loss: 1.8927 - val_acc: 0.5992\n",
      "Epoch 114/120\n",
      "724/724 [==============================] - 0s - loss: 0.4284 - acc: 0.8508 - val_loss: 2.1736 - val_acc: 0.6074\n",
      "Epoch 115/120\n",
      "724/724 [==============================] - 0s - loss: 0.4753 - acc: 0.8577 - val_loss: 2.0426 - val_acc: 0.6364\n",
      "Epoch 116/120\n",
      "724/724 [==============================] - 0s - loss: 0.3280 - acc: 0.8881 - val_loss: 2.2347 - val_acc: 0.6240\n",
      "Epoch 117/120\n",
      "724/724 [==============================] - 0s - loss: 0.2892 - acc: 0.8950 - val_loss: 2.3249 - val_acc: 0.6281\n",
      "Epoch 118/120\n",
      "724/724 [==============================] - 0s - loss: 0.2533 - acc: 0.9144 - val_loss: 2.3779 - val_acc: 0.6198\n",
      "Epoch 119/120\n",
      "724/724 [==============================] - 0s - loss: 0.2556 - acc: 0.9088 - val_loss: 2.4421 - val_acc: 0.6446\n",
      "Epoch 120/120\n",
      "724/724 [==============================] - 0s - loss: 0.3845 - acc: 0.8826 - val_loss: 2.9252 - val_acc: 0.6240\n",
      "322/322 [==============================] - 0s     \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution1D, MaxPooling1D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# input params\n",
    "batch_size = 16\n",
    "nb_classes = 8\n",
    "nb_epoch = 120\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 50, 37\n",
    "\n",
    "# the dataset values are single dimension/channel of intensity\n",
    "img_channels = 1\n",
    "\n",
    "# load dataset\n",
    "givenX_train = np.load('X_train.npy')\n",
    "givenY_train = np.load('y_train.npy')\n",
    "givenX_test = np.load('X_test.npy')\n",
    "\n",
    "# split training set into subsets\n",
    "trainX, testX, trainY, testY = train_test_split(givenX_train, givenY_train, test_size=0.25, random_state=42)\n",
    "\n",
    "# use PCA to reduce the train/test data to eigenfaces\n",
    "n_components = 150\n",
    "pca = PCA(n_components = n_components, svd_solver='randomized', whiten=True).fit(trainX)\n",
    "trainXPCA = pca.transform(trainX)\n",
    "testXPCA = pca.transform(testX)\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "print('X_train shape:', trainXPCA.shape)\n",
    "print('X_test shape:', testXPCA.shape)\n",
    "print(trainXPCA.shape[0], 'train samples')\n",
    "print(testXPCA.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(trainY, nb_classes)\n",
    "Y_test = np_utils.to_categorical(testY, nb_classes)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print('Y_test shape:', Y_test.shape)\n",
    "\n",
    "# normalize\n",
    "#trainXPCA = trainXPCA.astype('float32')\n",
    "#testXPCA = testXPCA.astype('float32')\n",
    "#trainXPCA /= 255\n",
    "#testXPCA /= 255\n",
    "\n",
    "# reshape to fit data model (considering the sample and channel dimensions as well) [sample_size, channel_size, dimension]\n",
    "reshapedTrainX = trainXPCA.reshape((trainXPCA.shape[0],) + (1, trainXPCA.shape[1]))\n",
    "reshapedTestX = testXPCA.reshape((testXPCA.shape[0],) + (1, testXPCA.shape[1]))\n",
    "#reshapedTrainY = Y_train.reshape((-1,1))\n",
    "#reshapedTestY = Y_test.reshape((-1,1))\n",
    "\n",
    "# sequentially apply filters\n",
    "model = Sequential()\n",
    "\n",
    "# declare convolution shape with 32 convolution filters [channel_size, dimension]\n",
    "model.add(Convolution1D(32, 1, border_mode='same', input_shape=(1, trainXPCA.shape[1])))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution1D(32, 1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_length=1))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution1D(64, 1, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution1D(64, 1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_length=1))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# train the model using SGD + momentum\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# fit without data augmentation\n",
    "model.fit(reshapedTrainX, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          nb_epoch=nb_epoch,\n",
    "          validation_data=(reshapedTestX, Y_test),\n",
    "          shuffle=True)\n",
    "\n",
    "#If predict_classes fail, try all predict functions and get the one that returns you a 1d array \n",
    "givenXPCA = pca.transform(givenX_test)\n",
    "finalTestX = givenXPCA.reshape((givenXPCA.shape[0],) + (1, givenXPCA.shape[1]))\n",
    "predictedClasses = model.predict_classes(finalTestX, batch_size=batch_size)\n",
    "\n",
    "#Check if there are 322 entries or not\n",
    "#print (\"HELLO\",len(predictedClasses))\n",
    "   \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
